<!doctype html>
<html>

<head>
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.min.css">
    <link href="https://fonts.googleapis.com/css?family=Nunito" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
    <script src="jquery-3.2.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
    <script src="opencv.js" type="text/javascript"></script>
</head>

<body>
    <div id="banner-gradient" class="section no-pad-bot">
        <nav role="navigation" class="bg-none">
            <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo white-text">Shadowplay trainer</a>
            </div>
        </nav>
    </div>
    <div class="row">
        <div class="col s6 m4">
            <div>
                <h3>Hi there!</h3>
                <p>
                    Please help us acquire training data for our shadowplay project!
                    <br>
                    <i class="tiny material-icons">edit</i>You will need a webcam. Face it somewhere with a plain white background.
                    <br>
                    <i class="tiny material-icons">edit</i>Notice a rectangle region inside the preview feed? That's the playing region.
                    <br>
                    <i class="tiny material-icons">edit</i>With your hands in the region, cast a shadow like the one (with some variations) shown in the picture below.
                    <br>
                    <i class="tiny material-icons">edit</i>Hold still for a few seconds for the program to take a photo.
                    <br>
                    <i class="tiny material-icons">edit</i>If you're happy with the image, you will have a few seconds to press submit button before it disappears.
                </p>
            </div>
            <div class="col s6 m4">
                <img id="example" class="responsive-img" />
            </div>
        </div>
        <div id="display_container" class="col s6 m4">
        </div>
        <div id="sample_container" class="col s6 m4">
            <a id="submit_button" class="btn waves-effect waves-light orange">Submit</a>
        </div>
    </div>
    <footer class="page-footer light-red gram-footer">
        <div class="footer-copyright">
            <div class="container"><a href="http://bit.studio" class="white-text text-lighten-3"></a></div>
        </div>
    </footer>
    <!-- this page is generateded by Gramateria -->
    <script>
    function getParameterByName(name, url) {
        if (!url) url = window.location.href;
        name = name.replace(/[\[\]]/g, '\\$&');
        var regex = new RegExp('[?&]' + name + '(=([^&#]*)|&|#|$)'),
            results = regex.exec(url);
        if (!results) return null;
        if (!results[2]) return '';
        return decodeURIComponent(results[2].replace(/\+/g, ' '));
    }

    var zodiac = JSON.parse(getParameterByName('zodiac')) || false;
    var page_index = parseInt(Math.random() * 1000);
    var current_label = null;

    var puppetry_set = [
        { url: "shadow_puppetry/crane.jpg", label: 1 },
        { url: "shadow_puppetry/horse.png", label: 2 },
        { url: "shadow_puppetry/human.png", label: 3 },
        { url: "shadow_puppetry/tiger.png", label: 4 }
    ];

    var zodiac_set = [
        { url: "chinese_zodiac/dog.png", label: 1 },
        { url: "chinese_zodiac/dragon.png", label: 2 },
        { url: "chinese_zodiac/goat.png", label: 3 },
        { url: "chinese_zodiac/horse.png", label: 4 },
        { url: "chinese_zodiac/monkey.png", label: 5 },
        { url: "chinese_zodiac/ox.png", label: 6 },
        { url: "chinese_zodiac/pig.png", label: 7 },
        { url: "chinese_zodiac/rabbit_2.png", label: 8 },
        { url: "chinese_zodiac/rat.png", label: 9 },
        { url: "chinese_zodiac/rooster.png", label: 10 },
        { url: "chinese_zodiac/snake.png", label: 11 },
        { url: "chinese_zodiac/tiger.png", label: 12 }
    ];

    let height = 0;
    let width = 0;
    const FPS = 30;

    let canvasFrame = null;
    let context = null;
    let src = null;
    let dst = null;
    let ones = null;
    let zeros = null;
    let disp = null;
    let disp_warpped = null;
    let M = cv.matFromArray(2, 3, cv.CV_64FC1, [1, 0, 0, 0, 1, 0]);
    let capture_res = null;

    let focus = null;

    let disp_width = parseInt($(window).width() / 3 - 30);
    let disp_height = disp_width;

    let video = null;
    let package = null;

    // tracking
    let tx = -1;
    let ty = -1;
    let ta = 0.1;
    let epsilon = 100;
    let countdown = 2000;
    let stamp = new Date().getTime();
    let allow_capture = true;

    function in_criterior(x, y) {
        return (x - tx) * (x - tx) + (y - ty) * (y - ty) < epsilon;
    }

    function next_page() {
        package = null;
        focus = random_pos();
        set_M(focus);
        if (zodiac) {
            page_index = (page_index + 1) % (zodiac_set.length);
            current_label = zodiac_set[page_index].label;
            $("#example").attr('src', zodiac_set[page_index].url);
        } else {
            page_index = (page_index + 1) % (puppetry_set.length);
            current_label = puppetry_set[page_index].label;
            $("#example").attr('src', puppetry_set[page_index].url);
        }
    }

    $("#submit_button").click(submit);

    $(document).ready(function() {
        navigator.mediaDevices.getUserMedia({ video: { width: { min: 640 }, height: { min: 480 } }, audio: false })
            .then(function(stream) {
                init_webcam(640, 480, stream);
                next_page();
                setTimeout(processVideo, 0);
            })
            .catch(function(err) {
                console.log("An error occurred! " + err);
            });
    });


    function init_webcam(w, h, stream) {
        width = w;
        height = h;

        canvasElement = $('<canvas id="canvasOutput" width="' + disp_width + '" height="' + disp_height + '"></canvas>');
        $('#display_container').append(canvasElement);

        videoElement = $('<video id="videoInput" width="' + width + '" height="' + height + '"></video>');
        $('body').append(videoElement);
        videoElement.hide();

        canvasElement = $('<canvas id="canvasFrame" width="' + width + '" height="' + height + '"></canvas>');
        $('body').append(canvasElement);
        canvasElement.hide();

        capture_res = Math.min(width, height);
        dataElement = $('<canvas id="dataFrame" width="' + capture_res + '" height="' + capture_res + '"></canvas>');
        $('body').append(dataElement);
        dataElement.hide();

        previewElement = $('<canvas id="previewFrame" width="' + disp_width + '" height="' + disp_height + '"></canvas>');
        $('#sample_container').prepend(previewElement);

        rawFrame = document.getElementById("canvasOutput");
        previewFrame = document.getElementById("previewFrame");
        canvasFrame = document.getElementById("canvasFrame"); // canvasFrame is the id of <canvas>
        context = canvasFrame.getContext("2d");
        rawContext = rawFrame.getContext("2d");
        previewContext = previewFrame.getContext("2d");
        src = new cv.Mat(height, width, cv.CV_8UC4);
        dst = new cv.Mat(height, width, cv.CV_8UC1);
        ones = new cv.Mat(height, width, cv.CV_8UC1, new cv.Scalar(255, 255, 255, 255));
        zeros = new cv.Mat(height, width, cv.CV_8UC1, new cv.Scalar(0, 0, 0, 255));
        disp = new cv.Mat(height, width, cv.CV_8UC4, new cv.Scalar(255, 255, 255, 255));
        disp_warpped = new cv.Mat(disp_height, disp_width, cv.CV_8UC4, new cv.Scalar(255, 255, 255, 255));
        preview_image = new cv.Mat(disp_height, disp_height, cv.CV_8UC4);
        data_image = new cv.Mat(capture_res, capture_res, cv.CV_8UC4);

        video = document.getElementById("videoInput"); // video is the id of video tag
        video.srcObject = stream;
        video.play();
    }


    function processVideo() {
        let begin = Date.now();
        context.drawImage(video, 0, 0, width, height);
        src.data.set(context.getImageData(0, 0, width, height).data);
        cv.cvtColor(src, dst, cv.COLOR_RGBA2GRAY);
        cv.flip(dst, dst, 1);

        kernel = new cv.Size(5, 5)
        cv.blur(dst, dst, kernel)
        cv.threshold(dst, dst, 150, 255, cv.THRESH_TRIANGLE);
        cv.subtract(ones, dst, dst);

        let contours = new cv.MatVector();
        let hierarchy = new cv.Mat();
        cv.findContours(dst, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);

        var max_i = 0;
        var max_size = 0;
        for (let i = 0; i < contours.size(); ++i) {
            var temp = contours.get(i)
            if (temp.rows > max_size) {
                max_size = temp.rows;
                max_i = i;
            }
            temp.delete();
        }

        disp.setTo(new cv.Scalar(0, 0, 0, 255));
        let color = new cv.Scalar(255, 255, 255, 255);
        cv.drawContours(disp, contours, max_i, color, cv.FILLED, cv.LINE_8, hierarchy, 1);

        let cnt = contours.get(max_i);
        let Moments = cv.moments(cnt, false);
        let cx = Moments.m10 / Moments.m00;
        let cy = Moments.m01 / Moments.m00;

        // console.log(cx, tx, cy, ty);
        if (in_criterior(cx, cy)) {
            if (new Date().getTime() - stamp > countdown) {
                capture();
            }
        } else {
            stamp = new Date().getTime();
            allow_capture = true;
        }

        tx = tx * (1.0 - ta) + cx * ta;
        ty = ty * (1.0 - ta) + cy * ta;

        contours.delete();
        hierarchy.delete();

        cv.warpAffine(disp, disp_warpped, M, new cv.Size(disp_width, disp_height));
        cv.imshow("canvasOutput", disp_warpped); // canvasOutput is the id of another <canvas>;

        var dwcr = disp_width / capture_res;
        var dhcr = disp_height / capture_res;
        rawContext.strokeStyle = "blue";
        rawContext.rect((focus.x1 - focus.offset_x) * dwcr,
            (focus.y1 - focus.offset_y) * dhcr, (focus.x2 - focus.x1) * dwcr, (focus.y2 - focus.y1) * dhcr);
        rawContext.stroke();


        // schedule next one.
        let delay = 1000 / FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
    }
    // schedule first one.

    let min_res_percent = 0.3;
    let max_res_percent = 0.7;

    function random_pos() {
        var min_x = (width - capture_res) / 2;
        var min_y = (height - capture_res) / 2;

        var x1 = min_x + Math.random() * (1.0 - max_res_percent) * capture_res;
        var y1 = min_y + Math.random() * (1.0 - max_res_percent) * capture_res;
        var w = (min_res_percent + Math.random() * (max_res_percent - min_res_percent)) * capture_res;
        var y2 = Math.min(height, y1 + w);
        return {
            offset_x: min_x,
            offset_y: min_y,
            x1: x1,
            y1: y1,
            x2: x1 + w,
            y2: y2
        };
    }

    function set_M(rect) {
        var x1 = focus.offset_x;
        var y1 = focus.offset_y;
        var x2 = focus.offset_x + capture_res;
        var y2 = focus.offset_y + capture_res;

        let srcTri = cv.matFromArray(3, 1, cv.CV_32FC2, [x1, y1, x2, y1, x2, y2]);
        let dstTri = cv.matFromArray(3, 1, cv.CV_32FC2, [0, 0, disp_width, 0, disp_width, disp_height]);

        M.delete();
        M = cv.getAffineTransform(srcTri, dstTri);

        srcTri.delete();
        dstTri.delete();
    }

    function capture() {
        if (!allow_capture) return;
        allow_capture = false;
        let P = cv.matFromArray(2, 3, cv.CV_64FC1, [1, 0, -focus.offset_x, 0, 1, -focus.offset_y]);
        cv.warpAffine(disp, data_image, P, new cv.Size(capture_res, capture_res));
        
        cv.imshow("dataFrame", data_image);
        P.delete();
        package = {
            reference: new Date().getTime(),
            setname: (getParameterByName("setname") || "test") + (zodiac? "_zodiac": "_puppet"),
            image: dataFrame.toDataURL(),
            label: current_label,
            x1: focus.x1 - focus.offset_x,
            y1: focus.y1 - focus.offset_y,
            x2: focus.x2 - focus.offset_x,
            y2: focus.y2 - focus.offset_y
        };

        cv.resize(data_image, preview_image, new cv.Size(disp_width, disp_height));
        cv.imshow("previewFrame", preview_image);

        classify();
    }

    function submit() {

        if (package == null) return;

        $.post("/collect", package, function(data, status, xhr) {
            console.log(data);
            previewContext.clearRect(0, 0, disp_width, disp_height);
            next_page();
        });
    }

    function classify() {

        $.post("/classify", package, function(data, status, xhr) {
            console.log(data);
            
            var dwcr = disp_width / capture_res;
            var dhcr = disp_height / capture_res;
                
            var json = JSON.parse(data);
            for (var j = 0; j < json["classes"].length; ++j) {
                previewContext.fillStyle="#FFFFFF";
                previewContext.fillRect(40,35 + 20*j,40,20);
                previewContext.fillStyle="#000000";
                previewContext.font="18px Arial";
                previewContext.fillText(json["classes"][j].toString(), 50, 50 + 20*j);
            }

        });
    }
    </script>
</body>

</html>
